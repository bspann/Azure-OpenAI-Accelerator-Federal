{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6423f8f3-a592-4ee7-9969-39e38933be52",
      "metadata": {},
      "source": [
        "# Putting it all together"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06bf854d-94d7-4a65-952a-22c7999a9a9b",
      "metadata": {},
      "source": [
        "So far we have done the following on the prior Notebooks:\n",
        "\n",
        "- **Notebook 01**: We loaded the Azure Search Engine with enriched PDFs in index: \"cogsrch-index-files\"\n",
        "- **Notebook 02**: We loaded more information to the Search Engine this time using a CSV file with 52k rows/articles in index: \"cogsrch-index-csv\"\n",
        "- **Notebook 03**: We added AzureOpenAI GPT models to enhance the the production of the answer by using Utility Chains of LLMs\n",
        "- **Notebook 04**: We loaded a vector-based index with large/complex PDFs information , \"cogsrch-index-books-vector\"\n",
        "- **Notebook 05**: We added memory to our system in order to power a conversational Chat Bot\n",
        "- **Notebook 06**: We introduced Agents and Tools in order to be able to solve a more complex task: ask questions to Tabular datasets\n",
        "- **Notebook 07**: We used a SQL Agent in order to talk to a SQL Database directly\n",
        "- **Notebook 08**: We used another ReAct Agent in order to talk to the Bing Search API and create a Bing Chat Clone and implemented callbacks for real-time streaming and tool information\n",
        "\n",
        "\n",
        "We are missing one more thing: **How do we glue all these features together into a very smart GPT Smart Search Engine Chat Bot?**\n",
        "\n",
        "We want a virtual assistant for our company that can get the question, think what tool to use, then get the answer. The goal is that, regardless of the source of the information (Search Engine, Bing Search, SQL Database, CSV File, JSON File, etc), the Assistant can answer the question correctly using the right tool.\n",
        "\n",
        "In this Notebook we are going to create that \"brain\" Agent, that will understand the question and use the right tool to get the answer from the right source.\n",
        "\n",
        "Let's go.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b81551-92ac-4f08-9c00-ba11981c67c2",
      "metadata": {
        "gather": {
          "logged": 1697571099209
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.agents import ConversationalChatAgent, AgentExecutor, Tool\n",
        "from langchain.memory import CosmosDBChatMessageHistory\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import DocSearchTool, CSVTabularTool, SQLDbTool, ChatGPTTool, BingSearchTool, run_agent\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import CUSTOM_CHATBOT_PREFIX, CUSTOM_CHATBOT_SUFFIX \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\", override=True)\n",
<<<<<<< HEAD
        "\n",
=======
>>>>>>> ec00340 (cleared outputs and added override=True)
        "\n",
        "from IPython.display import Markdown, HTML, display \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "MODEL_DEPLOYMENT_NAME = os.environ[ \"AZURE_OPENAI_GPT4_DEPLOYMENT\" ] # Reminder: gpt-35-turbo models will create parsing errors and won't follow instructions correctly "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cd1e3e-8527-4a8f-ba90-e700ae7b20ad",
      "metadata": {
        "gather": {
          "logged": 1697571104312
        }
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_GPT4_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_GPT4_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b56a94-0471-41c3-b441-3a73ff5dedfc",
      "metadata": {},
      "source": [
        "### Get the Tools - Doc Search, CSV Agent, SQL Agent and  Web Search\n",
        "\n",
        "In the file `common/utils.py` we created Agent Tools Classes for each of the Functionalities that we developed in prior Notebooks. This means that we are not using `qa_with_sources` chain anymore as we did until notebook 5. Agents that Reason, Act and Reflect is the best way to create bots that comunicate with sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "643d1650-6416-46fd-8b21-f5fb298ec063",
      "metadata": {
        "gather": {
          "logged": 1697571113043
        }
      },
      "outputs": [],
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.5, max_tokens=1000)\n",
        "\n",
        "# Uncomment the below line if you want to see the responses being streamed/typed\n",
        "# llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.5, max_tokens=500, streaming=True, callback_manager=cb_manager)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafd5bf5-28ee-4edd-978b-384cce057257",
      "metadata": {
        "gather": {
          "logged": 1697571124282
        }
      },
      "outputs": [],
      "source": [
        "# DocSearchTool is our Custom Tool Class (Agent) created for Azure Cognitive Search + OpenAI searches\n",
        "text_indexes = [\"cogsrch-index-files\", \"cogsrch-index-csv\"]\n",
        "doc_search = DocSearchTool(llm=llm, indexes=text_indexes,\n",
        "                           k=10, similarity_k=4, reranker_th=1,\n",
        "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
        "                           callback_manager=cb_manager, return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec238c0-0a00-4f94-8a12-389221355f16",
      "metadata": {
        "gather": {
          "logged": 1697571130439
        }
      },
      "outputs": [],
      "source": [
        "vector_only_indexes = [\"cogsrch-index-books-vector\"]\n",
        "book_search = DocSearchTool(llm=llm, vector_only_indexes = vector_only_indexes,\n",
        "                           k=10, similarity_k=10, reranker_th=1,\n",
        "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
        "                           callback_manager=cb_manager, return_direct=True,\n",
        "                           # This is how you can edit the default values of name and description\n",
        "                           name=\"@booksearch\",\n",
        "                           description=\"useful when the questions includes the term: @booksearch.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0ae466-aff8-4cdf-80d3-ef2c61867fc7",
      "metadata": {
        "gather": {
          "logged": 1697571147282
        }
      },
      "outputs": [],
      "source": [
        "# BingSearchTool is a langchain Tool class to use the Bing Search API (https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)\n",
        "# www_search = BingSearchTool(llm=llm, k=5, callback_manager=cb_manager, return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78edb304-c4a2-4f10-8ded-936e9141aa02",
      "metadata": {
        "gather": {
          "logged": 1697571149808
        }
      },
      "outputs": [],
      "source": [
        "## CSVTabularTool is a custom Tool class crated to Q&A over CSV files\n",
        "file_url = \"./data/all-states-history.csv\"\n",
        "csv_search = CSVTabularTool(path=file_url, llm=llm, callback_manager=cb_manager, return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d54cc5-41bc-43c3-a91d-12fc3a2446ba",
      "metadata": {
        "gather": {
          "logged": 1697571154027
        }
      },
      "outputs": [],
      "source": [
        "## SQLDbTool is a custom Tool class created to Q&A over a MS SQL Database\n",
        "sql_search = SQLDbTool(llm=llm, k=30, callback_manager=cb_manager, return_direct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65465173-92f6-489d-9b48-58d109c5723e",
      "metadata": {
        "gather": {
          "logged": 1697571156325
        }
      },
      "outputs": [],
      "source": [
        "## ChatGPTTool is a custom Tool class created to talk to ChatGPT knowledge\n",
        "chatgpt_search = ChatGPTTool(llm=llm, callback_manager=cb_manager, return_direct=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179fc56a-b7e4-44a1-8b7f-68b2b4d02e13",
      "metadata": {},
      "source": [
        "### Variables/knobs to use for customization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f11831-7578-4326-b3b3-d9b073a7149d",
      "metadata": {},
      "source": [
        "As you have seen so far, there are many knobs that you can dial up or down in order to change the behavior of your GPT Smart Search engine application, these are the variables you can tune:\n",
        "\n",
        "- <u>llm</u>:\n",
        "  - **deployment_name**: this is the deployment name of your Azure OpenAI model. This of course dictates the level of reasoning and the amount of tokens available for the conversation. For a production system you will need gpt-4-32k. This is the model that will give you enough reasoning power to work with agents, and enough tokens to work with detailed answers and conversation memory.\n",
        "  - **temperature**: How creative you want your responses to be\n",
        "  - **max_tokens**: How long you want your responses to be. It is recommended a minimum of 500\n",
        "- <u>Tools</u>: To each tool you can add the following parameters to modify the defaults (set in utils.py), these are very important since they are part of the system prompt and determines what tool to use and when.\n",
        "  - **name**: the name of the tool\n",
        "  - **description**: when the brain agent should use this tool\n",
        "- <u>DocSearchTool</u>: \n",
        "  - **k**: The top k results per index from the text search action\n",
        "  - **similarity_k**: top k results combined from the vector search action\n",
        "  - **reranker_th**: threshold of the semantic search reranker. Picks results that are above the threshold. Max possible score=4\n",
        "- <u>BingSearchTool</u>:\n",
        "  - **k**: The top k results from the bing search action\n",
        "- <u>SQLDBTool</u>:\n",
        "  - **k**: The top k results from the SQL search action. Adds TOP clause to the query\n",
        "  \n",
        "in `utils.py` you can also tune:\n",
        "- <u>model_tokens_limit</u>: In this function you can edit what is the maximum allows of tokens reserve for the content. Remember that the remaining will be for the system prompt plus the answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ee1058-debb-4f97-92a4-999e0c4e0386",
      "metadata": {},
      "source": [
        "### Test the Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc11cb35-8817-4dd0-b123-27f9eb032f43",
      "metadata": {
        "gather": {
          "logged": 1697571193281
        }
      },
      "outputs": [],
      "source": [
        "# Test the Documents Search Tool with a question we know it doesn't have the knowledge for\n",
        "printmd(doc_search.run(\"what is the weather today in Dallas?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473222f1-b423-49f3-98e7-ab70dcf47bd6",
      "metadata": {
        "gather": {
          "logged": 1697571258989
        }
      },
      "outputs": [],
      "source": [
        "# Test the Document Search Tool with a question that we know it has the answer for\n",
        "printmd(doc_search.run(\"How Covid affects obese people? and elderly?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b1a8577-ac34-44ca-91ca-379a6647eb88",
      "metadata": {
        "gather": {
          "logged": 1697571407308
        }
      },
      "outputs": [],
      "source": [
        "printmd(book_search.run(\"What's the acronim of the main point of the book Made to Stick\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03839591-553c-46a0-846a-1c4fb96bf851",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the Bing Search Tool\n",
        "# printmd(www_search.run(\"Who are the family member names of the current president of India?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc64f3ee-96e4-4007-8a3c-2f017a615587",
      "metadata": {
        "gather": {
          "logged": 1697571429209
        }
      },
      "outputs": [],
      "source": [
        "# Test the CSV Tool\n",
        "printmd(csv_search.run(\"how many rows does the file have?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c809f8d7-2ed9-46d8-a73c-118da063cace",
      "metadata": {
        "gather": {
          "logged": 1697571465706
        }
      },
      "outputs": [],
      "source": [
        "# Test the SQL Search Tool\n",
        "printmd(sql_search.run(\"How many people in total died california in each state of the west coast in July 2020?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70501c2-03d0-4072-b451-ddb92f4add56",
      "metadata": {
        "gather": {
          "logged": 1697571476505
        }
      },
      "outputs": [],
      "source": [
        "# Test the ChatGPTWrapper Search Tool\n",
        "printmd(chatgpt_search.run(\"what is the function in python that allows me to get a random number?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0ff658-b75a-4960-8576-65472844ad05",
      "metadata": {},
      "source": [
        "### Define what tools are we going to give to our brain agent\n",
        "\n",
        "Go to `common/utils.py` to check the tools definition and the instructions on what tool to use when"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d018c884-5c91-4a35-90e3-6a5a6e510c25",
      "metadata": {
        "gather": {
          "logged": 1697571482403
        }
      },
      "outputs": [],
      "source": [
        "# tools = [www_search, sql_search, doc_search, book_search, chatgpt_search]\n",
        "tools = [sql_search, doc_search, book_search, chatgpt_search]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f91421-079d-4bdd-9c45-96a0977c6558",
      "metadata": {},
      "source": [
        "**Note**: Notice that since both the CSV file and the SQL Database have the same exact data, we are only going to use the SQLDBTool since it is faster and more reliable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc02389-cf52-4a5f-b4a1-2820ee5d8116",
      "metadata": {},
      "source": [
        "### Initialize the brain agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "502e8b37-7d17-4e0c-84ca-655ff88a30e8",
      "metadata": {
        "gather": {
          "logged": 1697571488629
        }
      },
      "outputs": [],
      "source": [
        "cosmos = CosmosDBChatMessageHistory(\n",
        "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
        "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
        "    )\n",
        "# prepare the cosmosdb instance\n",
        "cosmos.prepare_cosmos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6314c17-281e-4db8-a5ea-f2579c508454",
      "metadata": {
        "gather": {
          "logged": 1697571500268
        }
      },
      "outputs": [],
      "source": [
        "llm_a = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.5, max_tokens=500)\n",
        "agent = ConversationalChatAgent.from_llm_and_tools(llm=llm_a, tools=tools, system_message=CUSTOM_CHATBOT_PREFIX, human_message=CUSTOM_CHATBOT_SUFFIX)\n",
        "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=10, chat_memory=cosmos)\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0f1d3e-831e-4ee3-8ee5-c01a235d857b",
      "metadata": {
        "gather": {
          "logged": 1697571505037
        }
      },
      "outputs": [],
      "source": [
        "# Let's see the custom prompt prefix we created for our brain agent\n",
        "printmd(agent_chain.agent.llm_chain.prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe7b39c-3913-4633-a47b-e2dcd6fccc51",
      "metadata": {
        "gather": {
          "logged": 1697571518023
        }
      },
      "outputs": [],
      "source": [
        "# Also let's see the Prompt that the Agent uses to talk to the LLM\n",
        "printmd(agent_chain.agent.llm_chain.prompt.messages[2].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4904a07d-b857-45d7-86ac-c7cade3e9080",
      "metadata": {},
      "source": [
        "### Let's talk to our GPT Smart Search Engine chat bot now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b37988b-9fb4-4958-bc17-d58d8dac8bb7",
      "metadata": {
        "gather": {
          "logged": 1697571533563
        }
      },
      "outputs": [],
      "source": [
        "# This question should not use any tool, the brain agent should answer it without the use of any tool\n",
        "printmd(run_agent(\"hi, how are you doing today?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c89051-f947-4329-9bf6-14e3023236fd",
      "metadata": {
        "gather": {
          "logged": 1697571541230
        }
      },
      "outputs": [],
      "source": [
        "# This question should not use any tool either\n",
        "printmd(run_agent(\"what is your name?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebdc3ad9-ad59-4135-87f6-e86728a11b71",
      "metadata": {
        "gather": {
          "logged": 1697571582238
        }
      },
      "outputs": [],
      "source": [
        "printmd(run_agent(\"@bing, I need to take my girlfriend to dinner tonight in downtown Chicago. Please give me options for Italian and Sushi as well\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0b33f9-75fa-4a3e-b9d8-8fd30dbfd3fc",
      "metadata": {
        "gather": {
          "logged": 1697571602874
        }
      },
      "outputs": [],
      "source": [
        "printmd(run_agent(\"@chatgpt, tell me the formula in physics for momentum\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f354eb-884d-4fd3-842e-a8adc3b09a70",
      "metadata": {
        "gather": {
          "logged": 1697571712582
        }
      },
      "outputs": [],
      "source": [
        "printmd(run_agent(\"@docsearch, what can markov chains do?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "badebc1b-dbfe-4a92-93bd-9ff214c34e75",
      "metadata": {
        "gather": {
          "logged": 1697571744655
        }
      },
      "outputs": [],
      "source": [
        "printmd(run_agent(\"@sqlsearch, How many people died of covid in Texas in 2020?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410d398b-d589-4352-8c42-2df5be173498",
      "metadata": {
        "gather": {
          "logged": 1697571808253
        }
      },
      "outputs": [],
      "source": [
        "printmd(run_agent(\"@booksearch, I don't know how to say No to my kids, help me! What kind of boundaries should I set?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e88e91-f952-4c58-bbb0-adc49d795063",
      "metadata": {
        "gather": {
          "logged": 1697572056784
        }
      },
      "outputs": [],
      "source": [
        "printmd(run_agent(\"@bing, How do I cook a chocolate cake?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fcd6749-b36d-4b5c-be9c-e2f02f34d230",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This question although does not contain instructions for a tool, the brain agent decides what tool to use\n",
        "printmd(run_agent(\"What's a good place to dine today in downtown Seoul?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080cc28e-2130-4c79-ba7d-0ed702f0ea7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This question many times causes a parsing error, but we can still give the answer using the run_agent function\n",
        "# which handles the parsing error exception\n",
        "printmd(run_agent(\"@chatgpt, can you give me a javascript example of how to trim the spaces of a sentence?\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b82d20c5-4591-4d94-8af7-bae614685874",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This question should trigger our prompt safety instructions\n",
        "printmd(run_agent(\"Tell me a funny joke about the president\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ded8d9-0bfe-4e16-be3f-382271c120a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "printmd(run_agent(\"Thank you for the information, have a good day Jarvis!\", agent_chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e27665-4006-4ffe-b19e-3eae3636fae7",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_chain.memory.buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a54fc7-ec9b-4ced-9e17-c65d00aa97f6",
      "metadata": {},
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c48d899-bd7b-4081-a656-e8d9e597220d",
      "metadata": {},
      "source": [
        "Great!, We just built the GPT Smart Search Engine!\n",
        "In this Notebook we created the brain, the decision making Agent that decides what Tool to use to answer the question from the user. This is what was necessary in order to have an smart chat bot.\n",
        "\n",
        "We can have many tools to accomplish different tasks, including connecting to APIs, dealing with File Systems, and even using Humans as Tools. For more reference see [HERE](https://python.langchain.com/en/latest/modules/agents/tools.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9969ed7e-3680-4853-b750-675a42d3b9ea",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "It is time now to use all the functions and prompts build so far and build a Web application.\n",
        "The Next notebook will guide you on how to build:\n",
        "\n",
        "1) A Bot API Backend\n",
        "2) A Frontend UI with a Search and Webchat interfaces"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
